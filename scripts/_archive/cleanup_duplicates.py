import os
import urllib.parse

PAGES_DIR = "./KB/pages"

def cleanup_duplicates():
    if not os.path.exists(PAGES_DIR):
        print("âŒ ç›®éŒ„ä¸å­˜åœ¨")
        return

    print("ğŸš€ é–‹å§‹æ¸…ç†é‡è¤‡çš„ URL ç·¨ç¢¼æª”æ¡ˆ...")
    
    files = [f for f in os.listdir(PAGES_DIR) if f.endswith(".md")]
    
    removed_count = 0
    renamed_count = 0
    
    for filename in files:
        # 1. æª¢æŸ¥æ˜¯å¦ç¶“é URL ç·¨ç¢¼ (ç°¡å–®åˆ¤æ–·: å« %)
        if '%' in filename:
            try:
                decoded_filename = urllib.parse.unquote(filename)
            except:
                continue
            
            # å¦‚æœè§£ç¢¼å¾Œçš„æª”åè·ŸåŸæª”åä¸åŒ (ä»£è¡¨çœŸçš„æ˜¯ encoded)
            if decoded_filename != filename:
                src = os.path.join(PAGES_DIR, filename)
                dst = os.path.join(PAGES_DIR, decoded_filename)
                
                # 2. æª¢æŸ¥ç›®æ¨™ (è§£ç¢¼å¾Œ) æ˜¯å¦å·²å­˜åœ¨
                if os.path.exists(dst):
                    # ç›®æ¨™å·²å­˜åœ¨ï¼Œä»£è¡¨é€™æ˜¯é‡è¤‡çš„èˆŠæª” -> åˆªé™¤
                    print(f"ğŸ—‘ï¸  ç™¼ç¾é‡è¤‡ï¼Œåˆªé™¤ç·¨ç¢¼ç‰ˆæœ¬: {filename}")
                    try:
                        os.remove(src)
                        removed_count += 1
                    except OSError as e:
                        print(f"âŒ åˆªé™¤å¤±æ•—: {e}")
                else:
                    # ç›®æ¨™ä¸å­˜åœ¨ï¼Œé€™å¯èƒ½æ˜¯æ¼ç¶²ä¹‹é­š -> é‡å‘½å
                    # ä½†ä¹‹å‰ refine_notes æ‡‰è©²åšéé€™æ­¥ï¼Œå¯èƒ½æ˜¯æŸäº›ç‰¹æ®Šå­—å…ƒå°è‡´
                    print(f"ğŸ”„ ç™¼ç¾æœªè§£ç¢¼æª”æ¡ˆï¼ŒåŸ·è¡Œé‡å‘½å: {filename} -> {decoded_filename}")
                    try:
                        os.rename(src, dst)
                        renamed_count += 1
                    except OSError as e:
                        print(f"âŒ é‡å‘½åå¤±æ•—: {e}")

    print(f"\nğŸ‰ æ¸…ç†å®Œæˆï¼")
    print(f"  - åˆªé™¤ {removed_count} å€‹é‡è¤‡æª”æ¡ˆ")
    print(f"  - é‡å‘½å {renamed_count} å€‹éºç•™æª”æ¡ˆ")

if __name__ == "__main__":
    cleanup_duplicates()
