#!/usr/bin/env python3
"""
scripts/fix_tags_source.py
åŠŸèƒ½ï¼šä¸€æ¬¡æ€§æƒæ KB ç›®éŒ„ä¸‹çš„æ‰€æœ‰ .md æª”æ¡ˆï¼Œè§£æ Frontmatter ä¸¦æ¸…ç† Tags
ä½¿ç”¨æ–¹å¼ï¼š
    python3 scripts/fix_tags_source.py
"""

import os
import re
from pathlib import Path

KB_DIR = "./KB"

def clean_tags(tags_list):
    """
    æ¸…æ´—ã€æ­£è¦åŒ–ã€åˆä½µæ¨™ç±¤
    """
    if not tags_list: return []
    
    # 1. Blacklist (å…¨å°å¯«æ¯”å°)
    BLACKLIST = {
        "#", "æ³¨æ„çœ‹é€™è¡Œ", "é€™è¡Œå¯ä»¥ä¸å¯«", "", 
        "h1", "ul", "ol", "listtotable", "centered", "right", "justified", 
        "outline", "nospace", "imagecaption", "tablecaption", "book100",
        "simpro", "fusionflow", "æ—¥æœ¬", "é•·ç¯‡å°èªª", "ç¾å¯¦ä¸»ç¾©", "æ±äº¬", 
        "20ä¸–ç´€", "æ„›æƒ…", "ç²¾ç¥å®˜èƒ½ç—‡", "æ›¾æ”¹ç·¨é›»å½±"
    }
    
    # 2. Renames (Canonical Mapping)
    RENAMES = {
        "product manager ç”¢å“ç¶“ç†": "PM",
        "product plan ç”¢å“ä¼åŠƒ": "PM",
        "product manager": "PM",
        "product plan": "PM",
        "remnoteæ•™å­¸": "RemNote", 
    }
    
    cleaned = []
    seen = set()
    
    for tag in tags_list:
        t = str(tag).strip()
        if not t: continue
        
        # ç§»é™¤é–‹é ­ #
        t = t.lstrip("#")
        
        # basic check
        if t.lower() in BLACKLIST:
            continue
        
        # 3. Splitting (Atomic Tags: Prefix-based)
        # è¤‡åˆæ¨™ç±¤æ‹†åˆ†: Logseqç­†è¨˜æ³• -> Logseq, ç­†è¨˜æ³•
        PREFIXES = [
            "GraphRAG", "Heptabase", "Logseq", "Notion", "RemNote", "Obsidian", "AI"
        ]
        
        split_tags = [t]
        
        for p in PREFIXES:
            # Case-insensitive prefix match
            # å¦‚æœæ¨™ç±¤ä»¥ Prefix é–‹é ­ï¼Œä¸”é•·åº¦å¤§æ–¼ Prefix (è¡¨ç¤ºæœ‰ Suffix)
            if t.lower().startswith(p.lower()) and len(t) > len(p):
                suffix = t[len(p):]
                # ç°¡å–®æ¸…ç† Suffix é–‹é ­çš„é€£æ¥ç¬¦ (ä¾‹å¦‚ Logseq-custom -> custom)
                # ä½†å› ç‚ºä¹‹å‰çš„æ­¥é©Ÿç§»é™¤äº†é€£å­—è™Ÿ? ä¸ï¼Œé€™è£¡ t æ˜¯åŸå§‹ tag
                # å¦‚æœ suffix æ˜¯ "-abc", lstrip è®Šæˆ "abc"
                suffix = suffix.lstrip("- _")
                
                if suffix:
                   split_tags = [p, suffix]
                   break # åªæ‹†åˆ†ä¸€æ¬¡ï¼Œé¿å…å¤šé‡æ‹†åˆ†é‚è¼¯éæ–¼è¤‡é›œ
            
        for sub_tag in split_tags:
            st = sub_tag.strip()
            if not st: continue
            
            # Check Rename
            if st.lower() in RENAMES:
                st = RENAMES[st.lower()]
            
            # 4. Normalization (CamelCase & English-Chinese mixed)
            # CamelCase è™•ç†ï¼šå°‡ - æˆ– ç©ºæ ¼ åˆ†å‰²çš„å­—é¦–å¤§å¯«
            parts = re.split(r'[- ]+', st)
            normalized_parts = []
            for p in parts:
                if re.match(r'^[a-zA-Z0-9]+$', p): # ç´”è‹±æ–‡/æ•¸å­—éƒ¨åˆ†
                    if p.islower():
                        normalized_parts.append(p.capitalize())
                    else:
                        normalized_parts.append(p)
                else:
                    normalized_parts.append(p) # ä¸­æ–‡æˆ–å…¶ä»–
            
            final_tag = "".join(normalized_parts)
            
            # Final check
            if final_tag.lower() not in BLACKLIST and final_tag not in seen:
                cleaned.append(final_tag)
                seen.add(final_tag)
                
    return cleaned

def parse_tags_from_string(val):
    """è§£æ tags å­—ä¸²ï¼Œæ”¯æ´ list "[a, b]" æˆ– comma string "a, b" """
    val = val.strip()
    if val.startswith("[") and val.endswith("]"):
        clean = val.replace("[", "").replace("]", "").replace("'", "").replace('"', "")
        return [t.strip() for t in clean.split(",") if t.strip()]
    else:
        return [t.strip() for t in val.split(",") if t.strip()]

def process_file(filepath):
    """è®€å–ä¸¦ä¿®æ”¹æª”æ¡ˆä¸­çš„ tags"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•è®€å– {filepath}: {e}")
        return False

    modified = False
    new_lines = []
    
    i = 0
    in_yaml = False
    
    while i < len(lines):
        line = lines[i]
        stripped = line.strip()
        
        # ç°¡å–®åˆ¤å®š YAML å€å¡Š (åƒ…åœ¨æª”æ¡ˆé–‹é ­)
        if i == 0 and stripped == "---":
            in_yaml = True
            new_lines.append(line)
            i += 1
            continue
        if in_yaml and stripped == "---":
            in_yaml = False
            new_lines.append(line)
            i += 1
            continue
            
        # åˆ¤æ–·æ˜¯å¦ç‚º Tags è¡Œ
        # æ”¯æ´æ ¼å¼:
        # 1. tags: [a, b]  (YAML)
        # 2. tags: a, b    (YAML)
        # 3. tags:: a, b   (Logseq Page Property)
        # 4. - tags: a, b  (Logseq Block Property)
        # 5.   tags:: a, b (Logseq Indented Property)
        
        # Regex: 
        # ^\s*       :é–‹é ­ç©ºç™½
        # (?:[-*]\s*)+ :å¯é¸çš„ "- " æˆ– "* " æˆ– "-- " (non-capturing group, one or more times)
        # tags       :é—œéµå­—
        # (:|::)     :åˆ†éš”ç¬¦
        # \s+(.*)    :å…§å®¹
        
        # Modified to handle "-- tags" or "- - tags" typos
        match = re.match(r'^(\s*)((?:[-*]+\s*)+)?tags(:{1,2})\s+(.*)', line)
        
        if match:
            indent = match.group(1)
            dash = match.group(2) or ""
            sep = match.group(3)
            val = match.group(4)
            
            # è§£æ
            current_tags = parse_tags_from_string(val)
            cleaned_tags = clean_tags(current_tags)
            
            # é‡çµ„
            # å¦‚æœæ˜¯ List æ ¼å¼ ['a', 'b']ï¼ŒåŸæ¨£ä¿ç•™ List æ ¼å¼æ¯”è¼ƒå®‰å…¨?
            # ä½†ç‚ºäº†çµ±ä¸€ï¼Œè‹¥åŸæœ¬æ˜¯ List å­—ä¸²ï¼Œæˆ‘å€‘é‡çµ„æˆ List å­—ä¸²
            # è‹¥åŸæœ¬æ˜¯é€—è™Ÿåˆ†éš”ï¼Œå‰‡ç¶­æŒé€—è™Ÿåˆ†éš”
            
            is_bracket_list = val.strip().startswith("[") and val.strip().endswith("]")
            
            if is_bracket_list:
                # è½‰å› ['a', 'b'] æ ¼å¼
                # æ³¨æ„: Logseq æœ‰æ™‚ç”¨é›™å¼•è™Ÿï¼Œæœ‰æ™‚å–®å¼•è™Ÿ
                # é€™è£¡çµ±ä¸€ç”¨å–®å¼•è™Ÿ
                quoted_tags = [f"'{t}'" for t in cleaned_tags]
                new_val_str = "[" + ", ".join(quoted_tags) + "]"
            else:
                new_val_str = ", ".join(cleaned_tags)
                
            new_line_content = f"{indent}{dash}tags{sep} {new_val_str}\n"
            
            if sorted(current_tags) != sorted(cleaned_tags):
                print(f"  âœ¨ [Fixed] {filepath.name}: {val.strip()} -> {new_val_str}")
                modified = True
                new_lines.append(new_line_content)
            else:
                new_lines.append(line)
                
        else:
            new_lines.append(line)
            
        i += 1

    if modified:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.writelines(new_lines)
        return True
    return False

def main():
    print("ğŸš€ é–‹å§‹æ¸…ç† Logseq åŸå§‹æª”ä¸­çš„ Tags ...")
    count = 0
    for root, dirs, files in os.walk(KB_DIR):
        for file in files:
            if file.endswith(".md"):
                path = os.path.join(root, file)
                if process_file(Path(path)):
                    count += 1
    
    print(f"\nâœ… æ¸…ç†å®Œæˆï¼å…±ä¿®æ”¹äº† {count} å€‹æª”æ¡ˆã€‚")

if __name__ == "__main__":
    main()
