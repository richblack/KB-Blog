#!/usr/bin/env python3
"""
patch_original_url.py

å¾ WordPress API æŠ“å–æ–‡ç« çš„ original_urlï¼Œ
ä¸¦æ›´æ–°åˆ°ç¾æœ‰ KB/pages/ æª”æ¡ˆçš„ frontmatter ä¸­ï¼Œ
ä¸æœƒè¦†è“‹æ–‡ç« å…§å®¹ã€‚
"""

import requests
import os
import re
import yaml
from pathlib import Path

# --- é…ç½®å€ ---
SITE_URL = "https://uncle6.me"
KB_DIR = "./KB"
PAGES_DIR = os.path.join(KB_DIR, "pages")
PER_PAGE = 100  # æ¯æ¬¡æŠ“å–å¹¾ç¯‡

def fetch_all_posts():
    """å¾ WordPress API æŠ“å–æ‰€æœ‰æ–‡ç« çš„ title å’Œ link"""
    posts = []
    page = 1
    
    while True:
        url = f"{SITE_URL}/wp-json/wp/v2/posts"
        params = {
            'per_page': PER_PAGE,
            'page': page,
            '_fields': 'id,title,link,slug'
        }
        
        try:
            response = requests.get(url, params=params, timeout=30)
            if response.status_code == 400:
                break  # æ²’æœ‰æ›´å¤šé é¢
            response.raise_for_status()
            
            batch = response.json()
            if not batch:
                break
                
            for post in batch:
                posts.append({
                    'id': post['id'],
                    'title': post['title']['rendered'],
                    'link': post['link'],
                    'slug': post['slug']
                })
            
            print(f"  ğŸ“¥ å·²æŠ“å– {len(posts)} ç¯‡æ–‡ç« ...")
            page += 1
            
        except Exception as e:
            print(f"  âš ï¸  API éŒ¯èª¤: {e}")
            break
    
    return posts

def normalize_title(title):
    """æ­£è¦åŒ–æ¨™é¡Œä»¥ä¾¿æ¯”å°"""
    import html
    title = html.unescape(title)
    # ç§»é™¤ç‰¹æ®Šå­—å…ƒ
    title = re.sub(r'[ï¼š:ï½œ|â€“â€”]', '', title)
    title = re.sub(r'\s+', '', title)
    return title.lower()

def find_matching_file(title, files_map):
    """ç”¨æ­£è¦åŒ–æ¨™é¡Œæ¯”å°æª”æ¡ˆ"""
    normalized = normalize_title(title)
    return files_map.get(normalized)

def update_frontmatter(filepath, original_url):
    """æ›´æ–°æª”æ¡ˆçš„ frontmatterï¼ŒåŠ å…¥ original_url"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æª¢æŸ¥æ˜¯å¦å·²æœ‰ original_url
    if 'original_url:' in content:
        return False  # å·²å­˜åœ¨ï¼Œè·³é
    
    # æ‰¾åˆ° frontmatter çµæŸä½ç½®
    if not content.startswith('---'):
        return False
    
    end_marker = content.find('---', 3)
    if end_marker == -1:
        return False
    
    # åœ¨ draft: è¡Œå¾Œé¢æ’å…¥ original_url
    frontmatter = content[:end_marker]
    body = content[end_marker:]
    
    # æ‰¾åˆ° draft è¡Œä¸¦åœ¨å…¶å‰æ’å…¥
    if 'draft:' in frontmatter:
        frontmatter = frontmatter.replace('draft:', f'original_url: "{original_url}"\ndraft:')
    else:
        # æ²’æœ‰ draft è¡Œï¼Œå°±åœ¨ --- å‰æ’å…¥
        frontmatter = frontmatter.rstrip() + f'\noriginal_url: "{original_url}"\n'
    
    new_content = frontmatter + body
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    return True

def main():
    print("ğŸ”— æ­£åœ¨å¾ WordPress æŠ“å–æ–‡ç«  URL å°ç…§è¡¨...")
    
    # 1. æŠ“å–æ‰€æœ‰æ–‡ç« 
    posts = fetch_all_posts()
    print(f"ğŸ“Š å…±æŠ“å– {len(posts)} ç¯‡æ–‡ç« ")
    
    if not posts:
        print("âš ï¸  ç„¡æ³•æŠ“å–æ–‡ç« ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ– WordPress API")
        return
    
    # 2. å»ºç«‹æœ¬åœ°æª”æ¡ˆå°ç…§è¡¨
    files_map = {}
    for root, dirs, files in os.walk(PAGES_DIR):
        for f in files:
            if f.endswith('.md'):
                filepath = os.path.join(root, f)
                # å¾æª”æ¡ˆè®€å–æ¨™é¡Œ
                try:
                    with open(filepath, 'r', encoding='utf-8') as file:
                        content = file.read()
                        match = re.search(r'^title:\s*["\']?(.+?)["\']?\s*$', content, re.MULTILINE)
                        if match:
                            title = match.group(1).strip('"\'')
                            normalized = normalize_title(title)
                            files_map[normalized] = filepath
                except:
                    pass
    
    print(f"ğŸ“‚ æœ¬åœ°å…±æœ‰ {len(files_map)} å€‹æª”æ¡ˆ")
    
    # 3. æ¯”å°ä¸¦æ›´æ–°
    updated = 0
    skipped = 0
    not_found = 0
    
    for post in posts:
        filepath = find_matching_file(post['title'], files_map)
        
        if filepath:
            if update_frontmatter(filepath, post['link']):
                updated += 1
                print(f"  âœ… æ›´æ–°: {os.path.basename(filepath)}")
            else:
                skipped += 1
        else:
            not_found += 1
    
    print(f"\nğŸ“Š çµæœ: æ›´æ–° {updated} ç¯‡, è·³é {skipped} ç¯‡ (å·²å­˜åœ¨), æœªæ‰¾åˆ° {not_found} ç¯‡")
    print("ğŸ‰ å®Œæˆï¼è«‹åŸ·è¡Œ logseq_publish_agent.py é‡æ–°ç”Ÿæˆ _redirects")

if __name__ == "__main__":
    main()
